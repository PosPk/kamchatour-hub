"use strict";(()=>{var e={};e.id=844,e.ids=[844],e.modules={399:e=>{e.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},517:e=>{e.exports=require("next/dist/compiled/next-server/app-route.runtime.prod.js")},4496:(e,t,r)=>{r.r(t),r.d(t,{originalPathname:()=>l,patchFetch:()=>g,requestAsyncStorage:()=>d,routeModule:()=>u,serverHooks:()=>m,staticGenerationAsyncStorage:()=>c});var a={};r.r(a),r.d(a,{POST:()=>p});var o=r(3278),s=r(5002),n=r(4877),i=r(1309);async function p(e){try{let t=process.env.GROQ_API_KEY;if(!t)return i.NextResponse.json({error:"missing_groq_env"},{status:500});let r=await e.json(),a=await fetch("https://api.groq.com/openai/v1/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",Authorization:`Bearer ${t}`},body:JSON.stringify({model:r?.model||"llama-3.1-70b-versatile",temperature:r?.temperature??.2,max_tokens:r?.max_tokens??1200,messages:r?.messages||[]})}),o=await a.json();if(!a.ok)return i.NextResponse.json(o,{status:a.status});return i.NextResponse.json(o)}catch(e){return i.NextResponse.json({error:e?.message||"groq_failed"},{status:500})}}let u=new o.AppRouteRouteModule({definition:{kind:s.x.APP_ROUTE,page:"/api/ai/groq/route",pathname:"/api/ai/groq",filename:"route",bundlePath:"app/api/ai/groq/route"},resolvedPagePath:"/workspace/landing-web/src/app/api/ai/groq/route.ts",nextConfigOutput:"",userland:a}),{requestAsyncStorage:d,staticGenerationAsyncStorage:c,serverHooks:m}=u,l="/api/ai/groq/route";function g(){return(0,n.patchFetch)({serverHooks:m,staticGenerationAsyncStorage:c})}}};var t=require("../../../../webpack-runtime.js");t.C(e);var r=e=>t(t.s=e),a=t.X(0,[787,833],()=>r(4496));module.exports=a})();